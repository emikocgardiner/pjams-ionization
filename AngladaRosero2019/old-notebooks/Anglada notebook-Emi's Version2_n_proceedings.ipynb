{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import pickle\n",
    "from pprint import pprint as pp\n",
    "import seaborn as sns\n",
    "import sys, os\n",
    "VICO_loc = '/scratch/ecg6wm/VICO'\n",
    "Anglada_loc = VICO_loc+'/AngladaRosero2019'\n",
    "sys.path.append(Anglada_loc)\n",
    "from def_seds import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##VARR 07.19.17\n",
    "\n",
    "## Here I will plot only object within their mm core\n",
    "\n",
    "do_print= False\n",
    "do_plot= False\n",
    "\n",
    "\n",
    "\n",
    "#example: data_dict['18089-1732']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Yichen_models_dict_dir = Anglada_loc+'/AngladaData/Yichen_models_dict.p'\n",
    "Yichen_models_dict = pickle.load( open( Yichen_models_dict_dir, 'rb' ) )\n",
    "print('Yichen_models_dict keys:', Yichen_models_dict.keys())\n",
    "\n",
    "\n",
    "radio_SOMA_dict_dir = Anglada_loc+'/AngladaData/radio_SOMA_dict.p'\n",
    "radio_SOMA_dict = pickle.load( open( radio_SOMA_dict_dir, 'rb' ) )\n",
    "print('radio_SOMA_dict keys:', radio_SOMA_dict.keys())\n",
    "\n",
    "best_Yichen_fits_dict_dir_new_model_Kei = Anglada_loc+'/AngladaData/best_Yichen_fits_dict_new_model_Kei.p'\n",
    "best_Yichen_fits_dict_new_model_Kei = pickle.load( open( best_Yichen_fits_dict_dir_new_model_Kei, 'rb' ) )\n",
    "print('best_Yichen_fits_dict_new_model_Kei keys:', best_Yichen_fits_dict_new_model_Kei.keys())\n",
    "\n",
    "best_Yichen_fits_dict_dir = Anglada_loc+'/AngladaData/best_Yichen_fits_dict.p'\n",
    "best_Yichen_fits_dict = pickle.load( open( best_Yichen_fits_dict_dir, 'rb' ) )\n",
    "print('Yichen_models_dict keys:', Yichen_models_dict.keys())\n",
    "\n",
    "\n",
    "SOMA_sources_dir = Anglada_loc+'/AngladaData/SOMA_sources.npy'\n",
    "SOMA_sources = np.load( SOMA_sources_dir )\n",
    "print('SOMA_source:', SOMA_sources)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#infile_M10 = 'AngladaData/mcore10.sigma1.dat'\n",
    "infile_M60 = Anglada_loc+'/AngladaData/mcore60.sigma1.dat'\n",
    "#infile_M1000 = 'AngladaData/mcore1000.sigma1.dat'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#M_star_M10, r_star_M10, L_star_M10, T_star_M10, Q_star_M10, rad_lum_star_M10 = \\\n",
    "#        pl.loadtxt(infile_M10, unpack=True ,usecols=[0, 1, 2, 3, 4, 5])\n",
    "\n",
    "M_star_M60, r_star_M60, L_star_M60, T_star_M60, Q_star_M60, rad_lum_star_M60 = \\\n",
    "        pl.loadtxt(infile_M60, unpack=True ,usecols=[0, 1, 2, 3, 4, 5])\n",
    "\n",
    "#M_star_M1000, r_star_M1000, L_star_M1000, T_star_M1000, Q_star_M1000, rad_lum_star_M1000 = \\\n",
    "#        pl.loadtxt(infile_M1000, unpack=True ,usecols=[0, 1, 2, 3, 4, 5])\n",
    "\n",
    "\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Table with bol luminosities from best models chi2\n",
    "\n",
    "lum_bol_tab = Anglada_loc+'/AngladaData/latex_tab_chi2_models_v3.txt'\n",
    "x=np.genfromtxt(lum_bol_tab,dtype=None,delimiter='&')\n",
    "L = [x1.decode('utf-8').replace('[9pt]','').lstrip('\\t').rstrip(' \\\\\\t').encode('utf-8') for x1 in x['f14']]\n",
    "aL = 1e4*np.array(L,dtype='float')\n",
    "for i,line in enumerate(x):\n",
    "\tif line['f0'] != '': source = line['f0']\n",
    "\telse: x[i]['f0'] = source\n",
    "\n",
    "sources=np.unique(x['f0'])\n",
    "L_dict={}\n",
    "for key in sources:\n",
    "    hits = np.where(x['f0'] == key)[0]\n",
    "#   print key, aL[hits[0]],min(aL[hits]),max(aL[hits])\n",
    "    L_key = key.strip().decode('utf-8').replace(' ','_').replace('$','').encode('utf-8')\n",
    "    for S_key in SOMA_sources:\n",
    "            \n",
    "        #print S_key, L_key\n",
    "        if S_key.startswith(L_key):\n",
    "                \n",
    "                L_key = S_key\n",
    "#           print 'replacing'\n",
    "#           print S_key,L_key\n",
    "        L_dict[L_key] = {}\n",
    "        L_dict[L_key]['best']=aL[hits[0]]\n",
    "#        if min(aL[hits]) == aL[hits[0]]:\n",
    "#            L_dict[L_key]['min']=min(aL[hits])*0.99            \n",
    "#        else:\n",
    "        L_dict[L_key]['min']=min(aL[hits]) \n",
    "        L_dict[L_key]['max']=max(aL[hits])\n",
    "\n",
    "for L_key in L_dict.keys():\n",
    "    print(L_key, L_dict[L_key]['min'],L_dict[L_key]['best'],L_dict[L_key]['max'])\n",
    "\n",
    "#this is not working correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAke errorbar array info in a dict\n",
    "# source: [best, min, max}\n",
    "L_excel_dict = {\n",
    "     b'AFGL_4029': {'best': 9700,  'min': 3400, 'max': 41000},\n",
    "     b'AFGL_437': {'best': 14000, 'min': 3000, 'max': 93000}, \n",
    "     b'Cepheus_A':{'best': 24000, 'min': 24000, 'max': 99000},\n",
    "     b'G35.20-0.74': {'best': 39000, 'min': 39000, 'max': 84000}, \n",
    "     b'G45.47+0.05': {'best': 460000, 'min': 172000, 'max': 509000},\n",
    "     b'IRAS_07299-1651': {'best': 20000, 'min': 10000, 'max': 42000}, \n",
    "     b'IRAS_20126+4104': {'best': 9000, 'min': 9000, 'max': 93000}, \n",
    "     b'NGC_7538_IRS9': {'best': 37000, 'min': 37000, 'max': 82000}\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating radio lum using 4.9 GHz data and for sources\n",
    "## with positive spectral index\n",
    "\n",
    "def Radio_Lum_calc( data_dict, data_dict_radio, this_source, this_comp ):\n",
    "\n",
    "    if data_dict_radio[ this_source ][ this_comp ]['Flux_4_9'] != '\\\\nodata' and \\\n",
    "       data_dict_radio[this_source][this_comp]['mm_associat'] == 'y' and\\\n",
    "           (data_dict_radio[ source ][ comp ]['Spec_ind'] != '\\\\nodata') and \\\n",
    "           (float( data_dict_radio[ source ][ comp ]['Spec_ind']) >= 0.2) and \\\n",
    "           (float( data_dict_radio[ source ][ comp ]['Spec_ind']) < 1.9):\n",
    "\n",
    "        \n",
    "        rad_lum_4_9 = (float( data_dict[ this_source ]['dist']))**2 * \\\n",
    "                   (float( data_dict_radio[ this_source ][ this_comp ]['Flux_4_9'] )*1e-3)\n",
    "        ##Radio luminosity just at 4.9 GHz I need the flux in mJy\n",
    "        log_rad_lum_4_9 = pl.log10(rad_lum_4_9)\n",
    "#        pdot_4_9 = 10*10**(-3.5)* rad_lum_4_9\n",
    "\n",
    "    else:\n",
    "        rad_lum_4_9 = 'nodata'\n",
    "        log_rad_lum_4_9 = 'nodata'\n",
    "#        pdot_4_9 = 'nodata'\n",
    "\n",
    "    return [this_source, this_comp, data_dict_radio[ this_source ][ this_comp ]['Flux_4_9'], \\\n",
    "                rad_lum_4_9, log_rad_lum_4_9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## New dictionary with the Literature tables\n",
    "\n",
    "data_dict_Lit = {}\n",
    "Lit_sources = []\n",
    "#infile='AngladaData/Reference_table.txt'\n",
    "infile=Anglada_loc+'/AngladaData/Reference_table.txt'\n",
    "\n",
    "##Reading the input from the table\n",
    "for line in open(infile, 'r'):\n",
    "    l1 = line.split()\n",
    "    if l1==[]: continue\n",
    "    skipChars = ['#']\n",
    "    if line[0] in skipChars: continue\n",
    "\n",
    "#    if not 'data_list' in locals(): data_list = [l1]\n",
    "#    else: data_list += [l1]\n",
    "    if not data_dict_Lit.__contains__( l1[0] ):\n",
    "            data_dict_Lit[ l1[0] ] = {}\n",
    "            Lit_sources.append( l1[0] )\n",
    "\n",
    "    data_dict_Lit[ l1[0] ] = {\n",
    "                              'Dist':   l1[1],\n",
    "                              'Flux':  l1[2],\n",
    "                              'Radio_lum': l1[3],\n",
    "                              'Lum_bol': l1[4],\n",
    "                              'Pdot': l1[5],\n",
    "                              'Refs':l1[6]}\n",
    "\n",
    "\n",
    "\n",
    "pickle.dump( data_dict_Lit, open( Anglada_loc+'/AngladaData/data_dict_Lit.p', 'wb' ) )\n",
    "np.save('Lit_sources', Lit_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating Pdot from data\n",
    "## scale factor from 1.8 cm to 6 cm = 2.06\n",
    "## see my notebook for details\n",
    "def Pdot_calc( data_dict_Lit, this_source, scale_factor = 1.0):\n",
    "\n",
    "    if data_dict_Lit[ this_source ]['Flux'] != 'na':\n",
    "        rad_lum_Lit = (float( data_dict_Lit[ this_source ]['Dist']))**2 * \\\n",
    "                   (float( data_dict_Lit[ this_source ]['Flux'] )*1e-3)/scale_factor\n",
    "        ##Radio luminosity I need the flux in mJy\n",
    "#        Pdot_Lit = 10*10**(-3.5)* rad_lum_Lit\n",
    "\n",
    "    else:\n",
    "        rad_lum_Lit = 'na'\n",
    "#        Pdot_Lit = 'na'\n",
    "\n",
    "    return [this_source, data_dict_Lit[ this_source ]['Flux'], \\\n",
    "                rad_lum_Lit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Scaife's sources\n",
    "if do_print: print('## Source          Flux(uJy)   Rad_Lum      Pdot')\n",
    "###Scaife sources fluxes are at 1.8 cm, therefore I need to scale it\n",
    "for source in Lit_sources:\n",
    "    if data_dict_Lit[ source ]['Refs'] == 'Scaife_2011' or \\\n",
    "       data_dict_Lit[ source ]['Refs'] == 'Scaife_2012':\n",
    "\n",
    "        Sc_ret = Pdot_calc( data_dict_Lit, source, 2.06)\n",
    "        ##Adding the new parameters to the dictionary for each source\n",
    "        data_dict_Lit[ source ].update({'Rad_Lum_calc': Sc_ret[2]})\n",
    " \n",
    "\n",
    "        line1 = '%-18.22s %-10.5s  %8.2e   '%( tuple(Sc_ret) )\n",
    "        if do_print: print(line1)\n",
    "##################\n",
    "\n",
    "################## Moscadelli et al 2016 sources\n",
    "if do_print: print('## Source          Flux(uJy)   Rad_Lum      Pdot')\n",
    "### sources fluxes are at  C-band, therefore I don't need to scale it\n",
    "for source in Lit_sources:\n",
    "    if data_dict_Lit[ source ]['Refs'] == 'Mosca_2016':\n",
    "\n",
    "        Mosca_ret = Pdot_calc( data_dict_Lit, source, 1.0)\n",
    "        ##Adding the new parameters to the dictionary for each source\n",
    "        data_dict_Lit[ source ].update({'Rad_Lum_calc': Mosca_ret[2]})\n",
    " \n",
    "\n",
    "        line1 = '%-18.22s %-10.5s  %8.2e   '%( tuple(Mosca_ret) )\n",
    "        if do_print: print(line1)\n",
    "##################\n",
    "        \n",
    "\n",
    "################## Rest of sources\n",
    "\n",
    "if do_print: print('\\n \\n')\n",
    "if do_print: print('## Source          Flux(uJy)   Rad_Lum      Pdo')\n",
    "### The rest of sources: I am not scaling them:\n",
    "for source in Lit_sources:\n",
    "    \n",
    "    if not data_dict_Lit[ source ]['Refs'] == 'Scaife_2011' and \\\n",
    "       data_dict_Lit[ source ]['Refs'] != 'Scaife_2012' and \\\n",
    "       data_dict_Lit[ source ]['Flux'] != 'na':\n",
    "\n",
    "        Others_ret = Pdot_calc( data_dict_Lit, source, 1.)  ## this apply pretty much to Ang92, Rod08 and Kurtz95\n",
    "        ##Adding the new parameters to the dictionary for each source\n",
    "        data_dict_Lit[ source ].update({'Rad_Lum_calc': Others_ret[2]})\n",
    "\n",
    "\n",
    "        line1 = '%-18.22s %-10.5s  %8.2e  '%( tuple(Others_ret) )\n",
    "        if do_print: print(line1)\n",
    "\n",
    "##################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "\n",
    "## Lyman Continuum line: data from Thompson 1984\n",
    "\n",
    "##Thompson 1984\n",
    "\n",
    "logL_Th, logNe_Th, logNL_Th = [], [], []\n",
    "\n",
    "\n",
    "##Reading the input from the table\n",
    "infile=Anglada_loc+'/AngladaData/'\n",
    "for line in open(infile+'INPUT_Thompson_1984.txt', 'r'):\n",
    "    l1 = line.split()\n",
    "    if l1==[]: continue\n",
    "    skipChars = ['#']\n",
    "    if line[0] in skipChars: continue\n",
    "    this_logL_Th= float(l1[0])\n",
    "    this_logNe_Th= float(l1[1])\n",
    "    this_logNL_Th= float(l1[2])\n",
    "\n",
    "    logL_Th.append( this_logL_Th )\n",
    "    logNe_Th.append( this_logNe_Th )\n",
    "    logNL_Th.append( this_logNL_Th )\n",
    "    \n",
    "\n",
    "\n",
    "##Calculating the number of Lyman cont photons\n",
    "##using equation from Monge\n",
    "T_e= 1e4    #K\n",
    "nu= 6.       #GHz at 5 cm\n",
    "\n",
    "\n",
    "rad_lum_Th=  2.08e-46 * 10**(np.array(logNL_Th))* nu**-0.1 * T_e**0.45   ##scaife 2012\n",
    "rad_lum_Th2= 1.32e-46 * 10**(np.array(logNL_Th))* nu**-0.1 * T_e**0.5   ##Solving from Kurtz et al. 1994\n",
    "\n",
    "## The equations are equivalent. I will use the one from Scaife 2012\n",
    "\n",
    "##################\n",
    "\n",
    "### Pdot is from Literature of my sources grouped in types\n",
    "\n",
    "def My_sources_plot_info( data_dict, source):\n",
    "    \n",
    "    if (data_dict[source]['Pdot_10e-3'] != '--') and \\\n",
    "       (data_dict[source].__contains__ ('Rad_Lum_4.9_Comps')):\n",
    "        \n",
    "        This_Pdot_from_Lit = float(data_dict[source]['Pdot_10e-3'])*1e-3\n",
    "        This_Rad_Lum_calc_4_9 = float(data_dict[source]['Rad_Lum_4.9_Comps'])\n",
    "        This_bol_Lum = data_dict[source]['Lum_bol']\n",
    "\n",
    "    else:\n",
    "        This_Pdot_from_Lit = '--'\n",
    "        This_Rad_Lum_calc_4_9 = '--'\n",
    "        This_bol_Lum = data_dict[source]['Lum_bol']\n",
    "        \n",
    "\n",
    "        \n",
    "    return [source, This_Pdot_from_Lit, This_Rad_Lum_calc_4_9, This_bol_Lum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "\n",
    "\n",
    "def Radio_Lum_calc_v2( data_dict, data_dict_radio, source, comp ):\n",
    "\n",
    "    if data_dict_radio[ source ][ comp ]['Flux_4_9'] != '\\\\nodata':\n",
    "        rad_lum_4_9 = (float( data_dict[ source ]['dist']))**2 * \\\n",
    "                   (float( data_dict_radio[ source ][ comp ]['Flux_4_9'] )*1e-3)\n",
    "        ##Radio luminosity just at 4.9 GHz I need the flux in mJy\n",
    "\n",
    "    else:\n",
    "        rad_lum_4_9 = 'nodata'\n",
    "\n",
    "    return [source, comp, data_dict_radio[ source ][ comp ]['Flux_4_9'], rad_lum_4_9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fig1\n",
    "                \n",
    "scale= 1.36    #scaling Anglada95 and slide talks data from 3.6 cm to 6 cm, assuming alpha=0.6\n",
    "\n",
    "\n",
    "\n",
    "pl.figure(9, figsize=(9,9))\n",
    "\n",
    "#sns.set(rc={\"figure.figsize\": (7.5,7.5)})\n",
    "#np.random.seed(sum(map(ord, \"palettes\")))\n",
    "#sns.palplot(sns.color_palette(\"hls\", 8))\n",
    "\n",
    "\n",
    "\n",
    "Fig9='Anglada_plot'\n",
    "fig9=pl.gcf()\n",
    "ax9 = fig9.add_axes([.15,.15, .8, .75])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(9, figsize=(9,9))\n",
    "ax = fig.add_axes([.15,.15,.8,.75])\n",
    "Fig = 'Anglada_plot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pl.loglog(10**np.array(logL_Th), rad_lum_Th,'-k', linewidth=3,label='_nolegend_',alpha=0.8)\n",
    "logL_bol_cl, logNe_05_cl, logNe_95_cl = [], [], []\n",
    "\n",
    "#cluster_file= 'AngladaData/lbin_cluster_Lbol-Nlym.dat'\n",
    "cluster_file= Anglada_loc+'/AngladaData/lbin_cluster_Lbol-Nlym.dat'\n",
    "\n",
    "\n",
    "##Reading the input from the table\n",
    "for line in open(cluster_file, 'r'):\n",
    "    l1 = line.split()\n",
    "    if l1==[]: continue\n",
    "    skipChars = ['#']\n",
    "    if line[0] in skipChars: continue\n",
    "    this_logL_bol_cl= float(l1[0])\n",
    "    this_logNe_05_cl= float(l1[1])\n",
    "    this_logNe_95_cl= float(l1[2])\n",
    "\n",
    "    logL_bol_cl.append( this_logL_bol_cl )\n",
    "    logNe_05_cl.append( this_logNe_05_cl )\n",
    "    logNe_95_cl.append( this_logNe_95_cl )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x= np.linspace(1, 1e6, 100)\n",
    "\n",
    "rad_lum_cesaroni_data=  2.08e-46 * 10**(np.array(logNe_95_cl))* nu**-0.1 * T_e**0.45 \n",
    "\n",
    "#pl.loglog(10**pl.array(logL_Th), 10**pl.array(logNL_Th), 'k-', linewidth=3)\n",
    "ax.loglog(10**pl.array(logL_bol_cl), rad_lum_cesaroni_data, 'k-', linewidth=3, color='olive')\n",
    "\n",
    "\n",
    "for source in Lit_sources:\n",
    "    \n",
    "##    if  data_dict_Lit[ source ]['Refs'] == 'Anglada_92' and \\\n",
    "##        data_dict_Lit[ source ]['Lum_bol'] != 'na': ## Nothing here\n",
    "##        \n",
    "##        Ang_92 = pl.loglog(float(data_dict_Lit[ source ]['Lum_bol']),\\\n",
    "##                data_dict_Lit[ source ]['Rad_Lum_calc'],'.y', markersize=16, \\\n",
    "##                markeredgewidth=1.5,alpha=0.5)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    if  data_dict_Lit[ source ]['Refs'] == 'Anglada_95'   and \\\n",
    "        data_dict_Lit[ source ]['Lum_bol'] != 'na':\n",
    "        \n",
    "        Ang_95 = ax.loglog(float(data_dict_Lit[ source ]['Lum_bol']),\\\n",
    "                float(data_dict_Lit[ source ]['Radio_lum'])/scale,'.y', markersize=16, \\\n",
    "                markeredgewidth=1.5,alpha=0.5)\n",
    "\n",
    "\n",
    "\n",
    "    scale_k = 0.95  ## asumming an ~flat spectrum -0.1\n",
    "\n",
    "## HII sources from Kurtz et al. 1994\n",
    "## These sources are at 3.6 cm, so I need to scale them to 6 cm\n",
    "    Unresolved_Kurtz_94= ['G10.841-2.592', 'G28.200-0.049', 'G48.61+0.02', 'G76.383-0.621',\\\n",
    "                      'G138.295+1.555', 'G189.030+0.784', 'G189.876+0.516',\\\n",
    "                      'G206.543-16.347']\n",
    "\n",
    "    if  data_dict_Lit[ source ]['Refs'] == 'Kurtz_94':\n",
    "        if source in Unresolved_Kurtz_94:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "##            Kur_94_U = pl.loglog(float(data_dict_Lit[ source ]['Lum_bol']),\\\n",
    "##                    float(data_dict_Lit[ source ]['Rad_Lum_calc']),'xk', markersize=10, \\\n",
    "##                    markeredgewidth=2.5,alpha=0.5)# Kurtz's HII regions\n",
    "        else:\n",
    "            Kur_94 = ax.loglog(float(data_dict_Lit[ source ]['Lum_bol']),\\\n",
    "                    float(data_dict_Lit[ source ]['Rad_Lum_calc'])/scale_k,'xk', markersize=10, \\\n",
    "                    markeredgewidth=2.5,alpha=0.5)# Kurtz's HII regions\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "\n",
    "# ## bol lum from the best model fit of Yichen\n",
    "# ## rad lum around 5 GHz\n",
    "\n",
    "\n",
    "# #other = ['Cepheus_A', 'G45.47+0.05']\n",
    "\n",
    "# #other = ['Cepheus_A']#, 'G45.47+0.05']\n",
    "\n",
    "# #other = ['AFGL_4029', 'AFGL_437', 'NGC_7538_IRS9']\n",
    "# other = ['AFGL_437', 'NGC_7538_IRS9']\n",
    "\n",
    "\n",
    "# ## scaled using their spectral indices in inner scale\n",
    "# ## I excluded AFGL 4029 since the alpha is 0.7 and the scale factor is 0.96 there is not much difference\n",
    "# scale_8GHz = 0.497  # alpha =1.38  \n",
    "# scale_5_3GHz = 0.94   # alpha = 1\n",
    "\n",
    "# ##gray #7f7f7f\n",
    "# new_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#0f0bc6',\n",
    "#               '#9467bd', '#8c564b', '#e377c2', '#d62728',\n",
    "#               '#bcbd22', '#17becf']\n",
    "# i=0\n",
    "# #for i in range(np.size(SOMA_sources))\n",
    "# for source in SOMA_sources:\n",
    "#     i=i+1\n",
    "    \n",
    "#     source = source.decode('UTF-8') #for running Python3\n",
    "#     flux= get_radio_data(source, 'A', 'Flux(Jy)')/1e-3   #mJy\n",
    "#     freq= get_radio_data(source, 'A', 'Freq')\n",
    "#     print(source, flux, freq)\n",
    "    \n",
    "    \n",
    "\n",
    "#     ##flux[1] is at ~5 GHz\n",
    "\n",
    "#     if (source not in other and source != 'Cepheus_A'):\n",
    "#         rad_lum_SOMA= Yichen_models_dict[source]['distance[kpc]']**2*flux[0]\n",
    "#         print(rad_lum_SOMA, source)\n",
    "# #         if( (source in Yichen_models_dict.keys())):  #NOTE I added these lines\n",
    "# # #             print('not missing:',source, flux[0], freq[0],rad_lum_SOMA, Yichen_models_dict[source]['best_bol_lum'])\n",
    "        \n",
    "# #             rad_lum_SOMA= Yichen_models_dict[source]['distance[kpc]']**2*\\\n",
    "# #                                                      flux[0]\n",
    "\n",
    "# # #     #        print(source, flux[1], freq[1],rad_lum_SOMA, Yichen_models_dict[source]['best_bol_lum'])\n",
    "# #             print('not missing:',source, flux[0], freq[0],rad_lum_SOMA, Yichen_models_dict[source]['best_bol_lum'])\n",
    "# #         else:\n",
    "# #         rad_lum_SOMA='missing' #until here\n",
    "\n",
    "\n",
    "        \n",
    "#     if source == 'Cepheus_A':\n",
    "        \n",
    "#         rad_lum_SOMA= Yichen_models_dict[source]['distance[kpc]']**2*\\\n",
    "#                                                      flux[0] * scale_8GHz\n",
    "\n",
    "\n",
    "#     elif source in other:\n",
    "# #         rad_lum_SOMA='missing'\n",
    "#         print(rad_lum_SOMA, source)\n",
    "#         rad_lum_SOMA= Yichen_models_dict[source]['distance[kpc]']**2*\\\n",
    "#                                                      flux[0] * scale_5_3GHz       \n",
    "\n",
    "    \n",
    "#         print('other',source, flux[0], freq[0],rad_lum_SOMA, Yichen_models_dict[source]['best_bol_lum'])\n",
    "\n",
    "    \n",
    "#     if(rad_lum_SOMA != 'missing'):\n",
    "#         ax.errorbar( L_dict[source]['best'],rad_lum_SOMA,\\\n",
    "#                      xerr=[[L_dict[source]['best']-L_dict[source]['min']],\\\n",
    "#                            [L_dict[source]['max']-L_dict[source]['best']]],\\\n",
    "#                      ecolor=new_colors[i],elinewidth=2,capsize=7,capthick=3, alpha=0.5)\n",
    "\n",
    "#         SOMA_17 = ax.loglog(L_dict[source]['best'],\\\n",
    "#                     rad_lum_SOMA,'o', color=new_colors[i], markersize=14, \\\n",
    "#                     markeredgewidth=1.5,alpha=0.5,label=source)\n",
    "    \n",
    "#     ax.legend(loc=2, numpoints=1,prop=FontProperties(size='medium'), ncol=2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOMA_data = np.genfromtxt(Anglada_loc+'/AngladaData/SOMA_Radio_data_table_core_emi.csv', \n",
    "                        comments='#', delimiter=',', skip_header=1, \n",
    "                          dtype=('|S20', '|S2', '|S10', '|S10', float, float))\n",
    "source_names = np.zeros((len(SOMA_data)), dtype='|S20')\n",
    "source_freqs = np.zeros((len(SOMA_data)), dtype='object')\n",
    "source_fluxes = np.zeros((len(SOMA_data)), dtype='object')\n",
    "print(SOMA_data)\n",
    "for i in range(len(source_names)):\n",
    "    source_names[i] = SOMA_data[i][0]\n",
    "    source_freqs[i] = SOMA_data[i][4]\n",
    "    source_fluxes[i] = SOMA_data[i][5]\n",
    "    \n",
    "print('source_names:', source_names)\n",
    "print('source_freqs:', source_freqs)\n",
    "print('source_fluxes:', source_fluxes)\n",
    "\n",
    "\n",
    "def get_SOMA_data(source):\n",
    "#     print(np.where(source_names == source))\n",
    "    index = np.where(source_names == source)[0][0]\n",
    "    freq = source_freqs[index]\n",
    "    flux = source_fluxes[index]\n",
    "#     print('get_SOMA_data('+str(source)+') returns index=%d, freq=%fGHz, flux=%fJy' % (index, freq, flux))\n",
    "    return freq, flux\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "\n",
    "## bol lum from the best model fit of Yichen\n",
    "## rad lum around 5 GHz\n",
    "\n",
    "\n",
    "#other = ['Cepheus_A', 'G45.47+0.05']\n",
    "\n",
    "#other = ['Cepheus_A']#, 'G45.47+0.05']\n",
    "\n",
    "# other = ['AFGL_4029', 'AFGL_437', 'NGC_7538_IRS9']\n",
    "other = ['AFGL_437', 'NGC_7538_IRS9']\n",
    "\n",
    "\n",
    "## scaled using their spectral indices in inner scale\n",
    "## Viviana: I excluded AFGL 4029 since the alpha is 0.7 and the scale factor is 0.96 there is not much difference\n",
    "scale_8GHz = 0.497  # alpha =1.38  \n",
    "scale_5_3GHz = 0.94   # alpha = 1\n",
    "# Emi: What about those with 4.9GHz? G35.20-0.74 and IRAS 20126+4104. \n",
    "#      Is the scale close enough to 1 to not matter?\n",
    "\n",
    "##gray #7f7f7f\n",
    "new_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#0f0bc6',\n",
    "              '#9467bd', '#8c564b', '#e377c2', '#d62728',\n",
    "              '#bcbd22', '#17becf']\n",
    "i=0\n",
    "#for i in range(np.size(SOMA_sources))\n",
    "for source in SOMA_sources:\n",
    "    i=i+1\n",
    "    \n",
    "    print('\\n', source)\n",
    "    freq, flux = get_SOMA_data(source)\n",
    "    flux /= 1e-3 #mJy\n",
    "    print('flux:', (str(flux)+'mJy'), 'logflux:', (str(np.log10(flux))), 'freq:', (str(freq)+'GHz'))\n",
    "    \n",
    "    \n",
    "\n",
    "    ##flux[1] is at ~5 GHz\n",
    "\n",
    "    if (source not in other and source != 'Cepheus_A'):\n",
    "        rad_lum_SOMA= Yichen_models_dict[source.decode('utf-8')]['distance[kpc]']**2*flux\n",
    "#         print('rad_lum_SOMA for '+str(source)+':', rad_lum_SOMA)\n",
    "        print('scaled flux:', rad_lum_SOMA, 'log(scaled flux):', np.log10(rad_lum_SOMA))\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    if source == 'Cepheus_A':\n",
    "        \n",
    "        rad_lum_SOMA= Yichen_models_dict[source]['distance[kpc]']**2*\\\n",
    "                                                     flux * scale_8GHz\n",
    "        print('scaled flux:', rad_lum_SOMA, 'log(scaled flux):', np.log10(rad_lum_SOMA))\n",
    "\n",
    "\n",
    "    elif source in other:\n",
    "#         rad_lum_SOMA='missing'\n",
    "#         print(rad_lum_SOMA, source)\n",
    "        rad_lum_SOMA= Yichen_models_dict[source]['distance[kpc]']**2*\\\n",
    "                                                     flux * scale_5_3GHz      \n",
    "        print('scaled flux:', rad_lum_SOMA, 'log(scaled flux):', np.log10(rad_lum_SOMA))\n",
    "\n",
    "    \n",
    "#         print('other',source, flux, freq,rad_lum_SOMA, Yichen_models_dict[source]['best_bol_lum'])\n",
    "\n",
    "    \n",
    "\n",
    "    ax.errorbar( L_excel_dict[source]['best'],rad_lum_SOMA,\\\n",
    "                 xerr=[[L_excel_dict[source]['best']-L_excel_dict[source]['min']],\\\n",
    "                       [L_excel_dict[source]['max']-L_excel_dict[source]['best']]],\\\n",
    "                 ecolor=new_colors[i],elinewidth=2,capsize=7,capthick=3, alpha=0.5)\n",
    "#     print('xerr = ', [[L_excel_dict[source]['best']-L_excel_dict[source]['min']],\\\n",
    "#                        [L_excel_dict[source]['max']-L_excel_dict[source]['best']]])\n",
    "#     print('L_excel_dict['+str(source)+'] = ', L_excel_dict[source])\n",
    "#     print(L_excel_dict[source]['best'] - L_excel_dict[source]['min'])\n",
    "\n",
    "    SOMA_17 = ax.loglog(L_excel_dict[source]['best'],\\\n",
    "                rad_lum_SOMA,'o', color=new_colors[i], markersize=14, \\\n",
    "                markeredgewidth=1.5,alpha=0.5,label=source.decode('utf-8'))\n",
    "leg1 = ax.legend(loc=2, numpoints=1,prop=FontProperties(size='medium'), ncol=2)\n",
    "\n",
    "# leg2= fig.legend([Ang_95[0], Kur_94[0]],\\\n",
    "#               ['Jets low-Mass YSO: Anglada et al. 1995', 'UC/HC HII: Kurtz et al. 1994'],'lower right', \\\n",
    "#               prop=FontProperties(size='medium'), numpoints=1)\n",
    "leg2= ax.legend([Ang_95[0], Kur_94[0]],\\\n",
    "              ['Jets low-Mass YSO: Anglada et al. 1995', 'UC/HC HII: Kurtz et al. 1994'], \\\n",
    "              fontsize=12, numpoints=1, bbox_to_anchor=(.0,.85), loc='upper left',)\n",
    "leg2.get_frame().set_alpha(0.2)\n",
    "\n",
    "ax.text(.72,.89, r'ZAMS',fontsize=16, color='olive', transform=ax.transAxes)\n",
    "ax.text(.33, .05, r'YSO',fontsize=16, color='teal', transform=ax.transAxes)\n",
    "\n",
    "ax.set_ylabel(r'$S_{\\nu}d^{2}$ (mJy kpc$^{2}$)', fontsize=18)\n",
    "#ax.xlabel(r'L (L$_{\\odot}$)', fontsize=20)\n",
    "ax.set_xlabel(r'L$_{bol}$ (L$_{\\odot}$)', fontsize=16)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax.set_ylim(1e-4,1.0e6)\n",
    "ax.set_xlim(1e-1,1.45e6)\n",
    "\n",
    "ax.tick_params('both', length=10, width=1, which='major', right=True, top=True, direction='in')\n",
    "ax.tick_params('both', length=4, width=1, which='minor', right=True, top=True, direction='in')\n",
    "\n",
    "fig\n",
    "\n",
    "# Cepheus A looks too high, mine: flux: 6.85mJy (correct), scaled flux: 3.3565\n",
    "# IRAS_07299-1651 looks a tinyyy bit too low, mine: flux: 1.15mJy (matches), scaled flux: 3.3565"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##x0,x1 = ax6.get_xlim()\n",
    "##y0,y1 = ax6.get_ylim()\n",
    "##ax6.set_aspect(abs(x1-x0)/abs(y1-y0))\n",
    "\n",
    "## Theretical fit from the low mass sources\n",
    "plot_lum_v2= np.array(ax.get_xlim())\n",
    "#rad_lum_an_v2= 10**(-2.1)*plot_lum_v2**(0.6)\n",
    "rad_lum_an_v2= 8*10**(-3)*plot_lum_v2**(0.6)\n",
    "\n",
    "ax.loglog(plot_lum_v2, rad_lum_an_v2,'--k')#,color=mygray)#,'--b')\n",
    "ax.text(.05,.34,r'$S_{\\nu}d^{2} =\\,8 \\times 10^{-3}(L_{bol})^{0.6}$',\n",
    "        fontsize=16, rotation = 23, transform=ax.transAxes)\n",
    "\n",
    "label_size = 14\n",
    "xlabels = ax9.get_xticklabels()\n",
    "for item in xlabels: item.set_size(label_size)\n",
    "ylabels = ax9.get_yticklabels()\n",
    "for item in ylabels: item.set_size(label_size)\n",
    "ax.tick_params(labelsize=18)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##########\n",
    "\n",
    "\n",
    "## Tanaka's 2016 data\n",
    "#ax.loglog(L_star_M10, rad_lum_star_M10,'-', color= 'teal', linewidth=3,label='_nolegend_',alpha=0.8)\n",
    "ax.loglog(L_star_M60, rad_lum_star_M60,'-', color= 'teal', linewidth=3,label='_nolegend_',alpha=0.8)\n",
    "#ax.loglog(L_star_M1000, rad_lum_star_M1000,'-', color= 'teal', linewidth=3,label='_nolegend_',alpha=0.8)\n",
    "\n",
    "fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## # SHOCK STUFF 3 scales, complete\n",
    "# inc=7\n",
    "\n",
    "# from matplotlib import cm\n",
    "\n",
    "# data_in = np.genfromtxt(Anglada_loc+'/AngladaData/EmiShockData.csv', \n",
    "#                         comments='#', delimiter=',', skip_header=3)\n",
    "# snapshots = np.zeros((len(data_in)), dtype='object')\n",
    "# years = np.zeros((len(data_in)), dtype='object')\n",
    "# lsts = np.zeros((len(data_in)), dtype='object')\n",
    "# innerflux = np.zeros((len(data_in)), dtype='object')\n",
    "# innerfluxvar = np.zeros((len(data_in)), dtype='object')\n",
    "# midflux = np.zeros((len(data_in)), dtype='object')\n",
    "# midfluxvar = np.zeros((len(data_in)), dtype='object')\n",
    "# entireflux = np.zeros((len(data_in)), dtype='object')\n",
    "# entirefluxvar = np.zeros((len(data_in)), dtype='object')\n",
    "# mins = np.zeros((len(data_in)), dtype='object')\n",
    "# maxes = np.zeros((len(data_in)), dtype='object')\n",
    "# labels = np.zeros((len(data_in)), dtype='object')\n",
    "\n",
    "# for i in range(len(snapshots[:7])):\n",
    "#     snapshots[i] = ('Snap%03d' % data_in[i,0])\n",
    "#     years[i] = ('%d yrs' % data_in[i,1])\n",
    "#     lsts[i] = data_in[i,3]\n",
    "#     innerflux[i] = data_in[i,5] #average(log(fluxes))\n",
    "#     innerfluxvar[i] = data_in[i,6] # stdev(log(fluxes))\n",
    "#     midflux[i] = data_in[i,7]\n",
    "#     midfluxvar[i] = data_in[i,8]\n",
    "#     entireflux[i] = data_in[i,9]\n",
    "#     entirefluxvar[i] = data_in[i,10]\n",
    "#     print((np.log10(maxes[i]) - np.log10(innerflux[i])), (np.log10(innerflux[i])-np.log10(mins[i])))\n",
    "    \n",
    "# #min\n",
    "# innermins = innerflux - innerfluxvar #error min(log(fluxes))\n",
    "# innermins = 10**(innermins)\n",
    "# midmins = midflux - midfluxvar #error min(log(fluxes))\n",
    "# midmins = 10**(midmins)\n",
    "# entiremins = entireflux - entirefluxvar #error min(log(fluxes))\n",
    "# entiremins = 10**(entiremins)\n",
    "\n",
    "# #max\n",
    "# innermaxes= innerflux + innerfluxvar # error min(log(fluxes)) = 10^[mean(log(fluxes)) - stdev(log(fluxes))]\n",
    "# innermaxes = 10**(innermaxes)\n",
    "# midmaxes= midflux + midfluxvar # error min(log(fluxes)) = 10^[mean(log(fluxes)) - stdev(log(fluxes))]\n",
    "# midmaxes = 10**(midmaxes)\n",
    "# entiremaxes= entireflux + entirefluxvar # error min(log(fluxes)) = 10^[mean(log(fluxes)) - stdev(log(fluxes))]\n",
    "# entiremaxes = 10**(entiremaxes)\n",
    "\n",
    "# #flux\n",
    "# innerflux = 10**innerflux\n",
    "# midflux = 10**midflux\n",
    "# entireflux = 10**entireflux\n",
    "\n",
    "\n",
    "# shocklines = np.zeros((3), dtype='object')\n",
    "\n",
    "# l1, = ax.plot(lsts[:inc], innerflux[:inc], color='red', lw=2, label='1000 au Shock Simulation')\n",
    "# # labels[0] = '1000 au Shock Simulation'\n",
    "# l2, = ax.plot(lsts[:inc], midflux[:inc], color='lawngreen', lw=2, label='4000 au Shock Simulation', linestyle = 'dashed')\n",
    "# # labels[1] = '4000 au Shock Simulation'\n",
    "# l3, = ax.plot(lsts[:inc], entireflux[:inc], color='fuchsia', lw=2, label='25000 au Shock Simulation', linestyle = 'dashdot')\n",
    "# # labels[2] = '25000 au Shock Simulation'\n",
    "\n",
    "# # for i in range(len(snapshots[:7])):\n",
    "# #     print((np.log10(innerflux[i]) - np.log10(mins[i])), (np.log10(innerflux[i]) - np.log10(maxes[i])))\n",
    "    \n",
    "    \n",
    "\n",
    "# # colors = cm.get_cmap('rainbow_r')\n",
    "# # colors = np.array(['fuchsia', 'red', 'darkorange', 'lime', 'cyan', 'blue', 'darkviolet'])\n",
    "# markers = np.array(['o', 'v', 's', 'P', 'h', 'X', 'D'])\n",
    "# scatterpoints = np.zeros((10), dtype = object)\n",
    "# for i in range(len(snapshots[:inc])):\n",
    "    \n",
    "#     ax.errorbar(lsts[i], innerflux[i], yerr=[[innermins[i],innermaxes[i]]] , \n",
    "#                                    color = 'red', marker='D', ms=8, ecolor='red',elinewidth=2, capthick=3, alpha=0.5)\n",
    "#     ax.errorbar(lsts[i], midflux[i], yerr=[[midmins[i],midmaxes[i]]] , \n",
    "#                                    color = 'lawngreen', marker='D', ms=8, ecolor='lawngreen',elinewidth=2, capthick=3, alpha=0.5)\n",
    "#     ax.errorbar(lsts[i], entireflux[i], yerr=[[entiremins[i],entiremaxes[i]]] , \n",
    "#                                    color = 'fuchsia', marker='D', ms=8, ecolor='fuchsia',elinewidth=2, capthick=3, alpha=0.5)\n",
    "# #     print(snapshots[i], lsts[i], innerflux[i], innerfluxvar[i], maxes[i]-(innerflux[i]),\n",
    "# #          10**(innerflux[i])-mins[i])\n",
    "# #     labels[i] = years[i]\n",
    "\n",
    "# leg3 = ax.legend(handles = [l1,l2,l3], bbox_to_anchor=(.000,.75), loc='upper left', fontsize=12)\n",
    "# ax.add_artist(leg1)\n",
    "# ax.add_artist(leg2)\n",
    "# # ax.add_artist(leg3)\n",
    "# # ax.text(.46, .22, 'Simulated Shock Emissions', color='darkviolet', fontsize=20, transform=ax.transAxes)\n",
    "\n",
    "\n",
    "# fig\n",
    "\n",
    "# # where are the random error bars coming from?  \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOCK STUFF 3 scales, complete\n",
    "inc=7\n",
    "\n",
    "from matplotlib import cm\n",
    "\n",
    "data_in = np.genfromtxt(Anglada_loc+'/AngladaData/EmiShockData_n.csv', \n",
    "                        comments='#', delimiter=',', skip_header=3)\n",
    "snapshots = np.zeros((len(data_in)), dtype='object')\n",
    "years = np.zeros((len(data_in)), dtype='object')\n",
    "lsts = np.zeros((len(data_in)), dtype='object')\n",
    "innerflux = np.zeros((len(data_in)), dtype='object')\n",
    "innerfluxvar = np.zeros((len(data_in)), dtype='object')\n",
    "midflux = np.zeros((len(data_in)), dtype='object')\n",
    "midfluxvar = np.zeros((len(data_in)), dtype='object')\n",
    "entireflux = np.zeros((len(data_in)), dtype='object')\n",
    "entirefluxvar = np.zeros((len(data_in)), dtype='object')\n",
    "mins = np.zeros((len(data_in)), dtype='object')\n",
    "maxes = np.zeros((len(data_in)), dtype='object')\n",
    "labels = np.zeros((len(data_in)), dtype='object')\n",
    "\n",
    "for i in range(len(snapshots[:7])):\n",
    "    snapshots[i] = ('Snap%03d' % data_in[i,0])\n",
    "    years[i] = ('%d yrs' % data_in[i,1])\n",
    "    lsts[i] = data_in[i,3]\n",
    "    innerflux[i] = data_in[i,5] #average(log(fluxes))\n",
    "    innerfluxvar[i] = data_in[i,6] # stdev(log(fluxes))\n",
    "    midflux[i] = data_in[i,7]\n",
    "    midfluxvar[i] = data_in[i,8]\n",
    "    entireflux[i] = data_in[i,9]\n",
    "    entirefluxvar[i] = data_in[i,10]\n",
    "    print((np.log10(maxes[i]) - np.log10(innerflux[i])), (np.log10(innerflux[i])-np.log10(mins[i])))\n",
    "    \n",
    "#min\n",
    "innermins = innerflux - innerfluxvar #error min(log(fluxes))\n",
    "innermins = 10**(innermins)\n",
    "midmins = midflux - midfluxvar #error min(log(fluxes))\n",
    "midmins = 10**(midmins)\n",
    "entiremins = entireflux - entirefluxvar #error min(log(fluxes))\n",
    "entiremins = 10**(entiremins)\n",
    "\n",
    "#max\n",
    "innermaxes= innerflux + innerfluxvar # error min(log(fluxes)) = 10^[mean(log(fluxes)) - stdev(log(fluxes))]\n",
    "innermaxes = 10**(innermaxes)\n",
    "midmaxes= midflux + midfluxvar # error min(log(fluxes)) = 10^[mean(log(fluxes)) - stdev(log(fluxes))]\n",
    "midmaxes = 10**(midmaxes)\n",
    "entiremaxes= entireflux + entirefluxvar # error min(log(fluxes)) = 10^[mean(log(fluxes)) - stdev(log(fluxes))]\n",
    "entiremaxes = 10**(entiremaxes)\n",
    "\n",
    "#flux\n",
    "innerflux = 10**innerflux\n",
    "midflux = 10**midflux\n",
    "entireflux = 10**entireflux\n",
    "\n",
    "\n",
    "\n",
    "l1, = ax.plot(lsts[:inc], innerflux[:inc], color='deepskyblue', lw=2, label='1000 au', linestyle = 'solid')\n",
    "l2, = ax.plot(lsts[:inc], midflux[:inc], color='lawngreen', lw=2, label='4000 au', linestyle = 'solid')\n",
    "l3, = ax.plot(lsts[:inc], entireflux[:inc], color='fuchsia', lw=2, label='25000 au', linestyle = 'solid')\n",
    "  \n",
    "for i in range(len(snapshots[:inc])):\n",
    "    ax.errorbar(lsts[i], innerflux[i], yerr=[[innermins[i],innermaxes[i]]] , \n",
    "                                   color = 'deepskyblue', marker='D', ms=8, ecolor='deepskyblue',elinewidth=2, capthick=3, alpha=0.5)\n",
    "    ax.errorbar(lsts[i], midflux[i], yerr=[[midmins[i],midmaxes[i]]] , \n",
    "                                   color = 'lawngreen', marker='D', ms=8, ecolor='lawngreen',elinewidth=2, capthick=3, alpha=0.5)\n",
    "    ax.errorbar(lsts[i], entireflux[i], yerr=[[entiremins[i],entiremaxes[i]]] , \n",
    "                                   color = 'fuchsia', marker='D', ms=8, ecolor='fuchsia',elinewidth=2, capthick=3, alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOCK STUFF 3 scales, complete\n",
    "inc=7\n",
    "\n",
    "from matplotlib import cm\n",
    "\n",
    "data_in = np.genfromtxt(Anglada_loc+'/AngladaData/EmiShockData_n_ratio.csv', \n",
    "                        comments='#', delimiter=',', skip_header=3)\n",
    "snapshots = np.zeros((len(data_in)), dtype='object')\n",
    "years = np.zeros((len(data_in)), dtype='object')\n",
    "lsts = np.zeros((len(data_in)), dtype='object')\n",
    "innerflux = np.zeros((len(data_in)), dtype='object')\n",
    "innerfluxvar = np.zeros((len(data_in)), dtype='object')\n",
    "midflux = np.zeros((len(data_in)), dtype='object')\n",
    "midfluxvar = np.zeros((len(data_in)), dtype='object')\n",
    "entireflux = np.zeros((len(data_in)), dtype='object')\n",
    "entirefluxvar = np.zeros((len(data_in)), dtype='object')\n",
    "mins = np.zeros((len(data_in)), dtype='object')\n",
    "maxes = np.zeros((len(data_in)), dtype='object')\n",
    "labels = np.zeros((len(data_in)), dtype='object')\n",
    "\n",
    "for i in range(len(snapshots[:7])):\n",
    "    snapshots[i] = ('Snap%03d' % data_in[i,0])\n",
    "    years[i] = ('%d yrs' % data_in[i,1])\n",
    "    lsts[i] = data_in[i,3]\n",
    "    innerflux[i] = data_in[i,5] #average(log(fluxes))\n",
    "    innerfluxvar[i] = data_in[i,6] # stdev(log(fluxes))\n",
    "    midflux[i] = data_in[i,7]\n",
    "    midfluxvar[i] = data_in[i,8]\n",
    "    entireflux[i] = data_in[i,9]\n",
    "    entirefluxvar[i] = data_in[i,10]\n",
    "    print((np.log10(maxes[i]) - np.log10(innerflux[i])), (np.log10(innerflux[i])-np.log10(mins[i])))\n",
    "    \n",
    "#min\n",
    "innermins = innerflux - innerfluxvar #error min(log(fluxes))\n",
    "innermins = 10**(innermins)\n",
    "midmins = midflux - midfluxvar #error min(log(fluxes))\n",
    "midmins = 10**(midmins)\n",
    "entiremins = entireflux - entirefluxvar #error min(log(fluxes))\n",
    "entiremins = 10**(entiremins)\n",
    "\n",
    "#max\n",
    "innermaxes= innerflux + innerfluxvar # error min(log(fluxes)) = 10^[mean(log(fluxes)) - stdev(log(fluxes))]\n",
    "innermaxes = 10**(innermaxes)\n",
    "midmaxes= midflux + midfluxvar # error min(log(fluxes)) = 10^[mean(log(fluxes)) - stdev(log(fluxes))]\n",
    "midmaxes = 10**(midmaxes)\n",
    "entiremaxes= entireflux + entirefluxvar # error min(log(fluxes)) = 10^[mean(log(fluxes)) - stdev(log(fluxes))]\n",
    "entiremaxes = 10**(entiremaxes)\n",
    "\n",
    "#flux\n",
    "innerflux = 10**innerflux\n",
    "midflux = 10**midflux\n",
    "entireflux = 10**entireflux\n",
    "\n",
    "\n",
    "\n",
    "l4, = ax.plot(lsts[:inc], innerflux[:inc], color='deepskyblue', lw=2, label=r'1000 au $t_\\mathrm{cool}/t_\\mathrm{flow}$', linestyle='dotted')\n",
    "l5, = ax.plot(lsts[:inc], midflux[:inc], color='lawngreen', lw=2, label=r'4000 au $t_\\mathrm{cool}/t_\\mathrm{flow}$', linestyle = 'dotted')\n",
    "l6, = ax.plot(lsts[:inc], entireflux[:inc], color='fuchsia', lw=2, label=r'25000 au $t_\\mathrm{cool}/t_\\mathrm{flow}$', linestyle = 'dotted')\n",
    "  \n",
    "for i in range(len(snapshots[:inc])):\n",
    "    ax.errorbar(lsts[i], innerflux[i], yerr=[[innermins[i],innermaxes[i]]] , \n",
    "                                   color = 'deepskyblue', marker='o', ms=8, ecolor='deepskyblue',elinewidth=2, capthick=3, alpha=0.5)\n",
    "    ax.errorbar(lsts[i], midflux[i], yerr=[[midmins[i],midmaxes[i]]] , \n",
    "                                   color = 'lawngreen', marker='o', ms=8, ecolor='lawngreen',elinewidth=2, capthick=3, alpha=0.5)\n",
    "    ax.errorbar(lsts[i], entireflux[i], yerr=[[entiremins[i],entiremaxes[i]]] , \n",
    "                                   color = 'fuchsia', marker='o', ms=8, ecolor='fuchsia',elinewidth=2, capthick=3, alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # High Resolution Data\n",
    "# flux_ratio_1000_hr = np.array([0.004282,\n",
    "#                               0.000097,\n",
    "#                               0.001526])\n",
    "\n",
    "# flux_ratio_4000_hr = np.array([0.005285,\n",
    "#                               0.000325,\n",
    "#                               0.001951])\n",
    "\n",
    "# flux_ratio_32000_hr = np.array([0.191204,\n",
    "#                               0.129702,\n",
    "#                               0.070682])\n",
    "\n",
    "# l12, = ax.plot(lsts[:3], flux_ratio_1000_hr, color='blue', lw=2, label='1000 au hi-res', \n",
    "#                marker='*', markersize=15, linestyle = 'dotted')\n",
    "# l11, = ax.plot(lsts[:3], flux_ratio_4000_hr, color='darkgreen', lw=2, label='4000 au hi-res', \n",
    "#                marker = '*', markersize=15, linestyle = 'dotted')\n",
    "# l10, = ax.plot(lsts[:3], flux_ratio_32000_hr, color='darkviolet', lw=2, label='entire snap hi-res', \n",
    "#                marker = '*', markersize=15, linestyle = 'dotted')\n",
    "\n",
    "    \n",
    "    \n",
    "leg3 = ax.legend(handles = [l1, l2, l3, l4, l5, l6], bbox_to_anchor=(.000,.75), loc='upper left', fontsize=12)\n",
    "ax.add_artist(leg1)\n",
    "ax.add_artist(leg2)\n",
    "# ax.add_artist(leg3)\n",
    "# ax.text(.46, .22, 'Simulated Shock Emissions', color='darkviolet', fontsize=20, transform=ax.transAxes)\n",
    "\n",
    "\n",
    "fig\n",
    "\n",
    "# where are the random error bars coming from?  \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pjams",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
